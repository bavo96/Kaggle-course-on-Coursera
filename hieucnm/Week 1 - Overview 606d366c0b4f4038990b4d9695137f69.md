# Week 1 - Overview

Created By: Hiếu Cao Nguyễn Minh
Last Edited: Aug 5, 2020 9:49 AM
Summary: Note some significant ideas from this course

# Week 1 - Overview

## 1. Competitions Platforms

Some other pages also host data science competitions as Kaggle: 

1. [*Driven Data*](https://www.drivendata.org/)
2. *[CodaLab](https://codalab.org/)*
3. *[IDAO](https://idao.world/)*
4. *[TopCoder](https://www.topcoder.com/challenges?filter[tags][0]=Data%20Science&filter[tracks][data_science]=true&tab=details)*
5. *[DataHack](https://datahack.analyticsvidhya.com/contest/all/)*
6. *[Tianchi](https://tianchi.aliyun.com/competition/gameList/activeList)*

## 2. Real world ML Pipeline

1. Understanding business problem
2. Problem formalization
3. Data collecting
4. Data preprocessing
5. Modelling
6. Deploy model
7. Monitoring
- Kaggle only focus on step 4,5 and sometime 3 of the pipeline.

## 3. Advices

1. **Not only model:** To win Kaggle or any data science competitions in general, the key is not the model, but is how much we understand our data. Instead of heuristically improve our model by this way that way, we should look deeply into our data to find the insights, which will direct us to some good ways of remarkable improvements.
2. **Be creative:** brandstorm our mind in multiple aspects. We should not assume that the best result can only be achieved by the best model. It's also about how we train, how we engineer features, and how we mine the data. Sometimes, only some analysis could bring you on top of leader board. Don't hesitate if you find a very complex algorithm, or a weird approach of training. Just try and error. Remember to think out of the box.

## 4. Recap of ML algos

1. Linear (include kernel-based like SVM)
2. kNN
3. Tree-based (most powerful for tabular data)
4. Neural Net (most powerful for unstructure data: images, text, ...)
- ***No free lunch***
- Hình dạng của Decision boundary của các thuật toán khác nhau (phải thuộc nằm lòng):
    1. Linear: split feature space into subspaces, boundaries are lines
    2. Tree-based: split feature space into boxes
    3. kNN: no split, depends heavily on which distance metric to use
    4. Neural Net: same as linear model but smoothly, boundaries are curves

![Week%201%20-%20Overview%20606d366c0b4f4038990b4d9695137f69/Untitled.png](Week%201%20-%20Overview%20606d366c0b4f4038990b4d9695137f69/Untitled.png)

Source : sklearn plot classifier comparision

## 5. Quiz about GDBT

- Will GDBT perform worse if we remove first/last tree ?

    Removing last tree will not hurt the performace.

    Removing first tree depends on learning rate: If learning rate is too large, performace will drop significantly, and vice versa.

## 6. Feature preprocessing: Numeric

- Scaling:
    - Not necessary for tree-based models.
    - With respect to non-tree-based models, we should apply scaling (MinMaxScaling, StandardScaling, ...) to ALL numeric features, so that all features will have roughly similar initial impact on model, prevent model from strongly depending on only some extreme features.
- Outlier handling:
    - Winsorization: numeric features (and also numeric target) by a upper bound (usually 99th percentile) and lower bound (usually 1st percentile), so that the feature distribution look fine.
    - Rank: will pull outliers closer to normal sample.
- Feature generation:
    - Log transform
    - Power transform
    - Get numbers after floating point, e.g. 3.92 → 0.92
    - ...

## 7. Feature preprocessing: Categorical

- Label Encoding:
    - work fine if the categorical feature contains ordinal meaning
    - we can encode by multiple orders: alphabet order, appearance order, ...
    - often used for tree-based models
- Count / Frequency Encoding:
    - work fine if the frequency of the categorical feature is correlated to the target
    - if it is, then this also help reduce number of split of tree-based models.
    - often used for tree-based models
    - can be applied on only train data or both train and test data (i.e: count the values on both train and test data to encode).
- One-hot encoding:
    - already scaling
    - hurt memory and make training/inference time slower if there are too many unique values of the categorical feature. We can overcome this by sparse matrix.
    - often used for non-tree-based models.
- Feature generation:
    - Combine multiple categorical features to form new one (e.g combine feature A (2 unique values) and B (3 unique values) to a new feature C (2*3 = 6 unique values), useful for non-tree based models.

## 8. Feature preprocessing: Datetime

There are different ways to generate feature from a datetime column:

- Time period: year, month, day-of-month, day-of-week, week-of-month, hour, minute, second, season, is_weekend, is_holiday, ...
- Time since: calculate a time range between current time to a specified time. Time range can be in seconds, days, or any period unit. There are 2 sub-types of this:
    - Row-independent: the specified time is the same for all sample. E.g: timestamp is calculated from current time to 00:00:00 UTC, 1st Jan 1970.
    - Row-dependent: the specified time is different for each sample. E.g: number of days left until next holidays, ...
- Time diff: difference between datetime columns.

![Week%201%20-%20Overview%20606d366c0b4f4038990b4d9695137f69/Untitled%201.png](Week%201%20-%20Overview%20606d366c0b4f4038990b4d9695137f69/Untitled%201.png)

Source: Coursera. Course: How to Win a Data Science Competition. Week 1 Video: Datetime and coordinates. An example of feature generation for datetime.

After generated, new features can be either numeric or categorical features. Depending on which kind they are, we should apply suitable preprocessing steps in the above section.

## 9. Feature preprocessing: Coordinate

Feature generation:

- Distance: find one or some specific points in our map and calcualte distance of each sample to those points. The specific points depend on each task, and we also have multiple ways to choose them.
    - in case we have a real map: the specific points can be hospitals, malls, or gates, ...
    - in case we dont have a map in our data, we can use coordinates in our whole training data to build a grid map, then use some techniques to find specific points:
        - we can use a clustering algorithm and consider the desired centers as those specific points.
        - or we can leverage statistics on other columns. E.g: we can use areas where there are many old buildings around, we can obtain this information if we have something like building_age column in our data; or we can use area having the highest average building prices (or population ...), we can obtain this infor if we have something line building_price coumn in our data; and so on ...
- If we are going to use tree-based models, one tricky for coordiate columns is that we can rotate the coordinates to have new features. The rotation degree cannot be known in advance, just try and error. This trick can work because tree-based models split data into boxes, number of splits can be reduced if features stand in the right place. Look at the example image below to clearly understand:

![Week%201%20-%20Overview%20606d366c0b4f4038990b4d9695137f69/Untitled%202.png](Week%201%20-%20Overview%20606d366c0b4f4038990b4d9695137f69/Untitled%202.png)

Source: Coursera. Course: How to Win a Data Science Competition. Week 1 Video: Datetime and coordinates. Number of splits could be only 1 if we rotate coordinate features in a right degree.

## 10. Missing values

- Missing values can be in form of NaN in our data, or the NaNs can be replaced in form of a specifial values that occur too many times, such as: empty string, -1, -999, a very large number, ... The most way to find out hidden NaNs in a column is:
    - with numeric: checking the historgam.
    - with categorical: checking the bar plot of value counts

- Ways to fillna:
    - *-1, -999, "miss"* : replace NaNs by a value outside of value range, or consider missing values as a seperate category. This method can be usefull for tree-based models, but not good for non-tree-based models.
    - *mean, median*: replace NaNs by mean or median of that non-missing values of that numeric column. Contrary, this method is beneficial for non-tree-based models, such as linear and neural nets, and not good for tree-based models.
    - reconstruct missing values somehow (check it later)
- Feature generation:
    - *f0_is_null* feature: a new feature indicating that a value of column *"f0"* is missing or not. **This is very useful for any models**.

- **Avoid feature generation after missing values imputation.** Because the imputed values (e.g: mean, -999, ...) can mislead our model. Let's see an example.
    - We have 2 columns: temperature  and date. Column temperature has NaN values. Now, we fill NaN values of temperature by mean.  Then, we generate a new feature that is the different temperature between 2 adjacent days.
    - The problem here: In natural sense, average temperature of a whole year will fall back into approximately zero. Therefore, missing values was imputed by zeros. So, our new feature will become abnormally large at rows where temperature of one of the two adjacent days is zero. This will hurt the learning process of our model. See the figure below to clearly understand.

    ![Week%201%20-%20Overview%20606d366c0b4f4038990b4d9695137f69/Untitled%203.png](Week%201%20-%20Overview%20606d366c0b4f4038990b4d9695137f69/Untitled%203.png)

    Source: Coursera. Course: How to Win a Data Science Competition. Week 1 Video: Handling missing values. Feature generation after NaN imputation can create wrong features.

- Some more trick for handling miss values:
    - Consider outliers as missing values.
    - Consider values that appear in train data but do not in test data as missing ones. This is a good approach because it forces our model to learn other aspects whenever it see those not-in-test-data values.
        - But if we tend to use count / frequency encoding for this column on both train and test data, we should not apply this trick. Because, if there is a relation between frequencies of value in this column with the target column, then removing the values can drop useful information for our model. See the example below:

![Week%201%20-%20Overview%20606d366c0b4f4038990b4d9695137f69/Untitled%204.png](Week%201%20-%20Overview%20606d366c0b4f4038990b4d9695137f69/Untitled%204.png)

Source: Coursera. Course: How to Win a Data Science Competition. Week 1 Video: Handling missing values. Example that removing not-in-test values can drop useful relation between frequency feature and target column.

## 11. Feature extraction: text

Approaches to extract feature from text:

- Bag of words: very large vectors, no meaning captured.
- Tf-Idf (old but gold): still very large vectors, captured importance of words in a document.

$$tf(t,d) = \frac{count(t,d)}{\max \{ count(w,d) : w \in d \}}$$

$$idf(t, D) = log \frac{ |D| }{| \{d \in D : t \in d \}|}$$

- Word embedding: small vectors, captured meaning of words, words having relationship (e.g: synonyms) will have corresponding vectors that are close (in term of euclidean / cosine distance) to each other.

Approaches to preprocess text data:

- Lowercase
- Leematization: turn plural nouns to singular nouns, verbs to base form.
- Stemming : remove different characters in the tail of similar words.
- Stopwords removal: remove words appear too many times.

---

---

# Quiz

I audit this course, so I cannot submit my answers of any Quizzes (not Practice Quizzes). However, I still finish the quizzes and write my answers as well as explanation here. 

If you did enroll the course and did not finish the quizzes, please do not read my answers, you should go back to the course and do it yourself. Otherwise, please do not hesitate to comment to share your answers or point out mistakes of mine.

## 1. Recap

6 *questions*

1. What back propagation is usually used for in neural networks?

*Answer:*

- To calculate gradient of the loss function with respect to the parameters of the network

2. Suppose we've trained a RandomForest model with 100 trees. Consider two cases:

1. We drop the first tree in the model
2. We drop the last tree in the model

We then compare models performance *on the train set*. Select the right answer.

*Answer:*

- In case 1 performace will be roughly the same as in the case 2

3. Suppose we've trained a GBDT model with 100 trees with a fairly large learning rate. Consider two cases:

1. We drop the first tree in the model
2. We drop the last tree in the model

We then compare models performance *on the train set*. Select the right answer.

*Answer:*

- In case 1 performace will drop more than in the case 2

4. Consider two cases:

1. We fit two RandomForestClassifiers 500 trees each and average their predicted probabilities on the test set.
2. We fit a RandomForestClassifier with 1000 trees and use it to get test set probabilities.

All hyperparameters except number of trees are the same for all models.

Select the right answer.

*Answer:*

- The quality of predictions in the case 1 will be roughly the same as the quality of the predictions in the case 2

5. What model was most probably used to produce such decision surface? Color (from white to purple) shows predicted probability for a point to be of class "red".

![Week%201%20-%20Overview%20606d366c0b4f4038990b4d9695137f69/Untitled%205.png](Week%201%20-%20Overview%20606d366c0b4f4038990b4d9695137f69/Untitled%205.png)

Source: Coursera. Course: How to Win a Data Science Competition. Week 1 Quiz: Recap. Question 5.

*Answer:*

- Decision Tree

6. What model was most probably used to produce such decision surface?

![Week%201%20-%20Overview%20606d366c0b4f4038990b4d9695137f69/Untitled%206.png](Week%201%20-%20Overview%20606d366c0b4f4038990b4d9695137f69/Untitled%206.png)

Source: Coursera. Course: How to Win a Data Science Competition. Week 1 Quiz: Recap. Question 6.

*Answer:*

- Random Forest

## 2. Graded Soft/Hard Quiz

4 *questions*

1. Which library provides the most convenient way to perform matrix multiplication?

*Answer:*

- Numpy

2. Which libraries contain implementations of linear models?

*Answer:*

- SkLearn

3. Which library (or libraries) are used to train a neural network?

*Answer:*

- PyTorch
- Keras
- Tensorflow

4. Select the correct statements about the RandomForest and GBDT models.

*Answer:*

- In GBDT each new tree is built to improve the previous trees.
- Trees in RandomForest can be constructed in parallel (that is how RandomForest from sklearn makes use of all your cores)

Explanation:

- In GDBT, because new tree based on the previous ones, there is no parallel process in constructing them. GDBT employ multiple CPUs in other processes, such as calculating impurity metrics (e.g: gini, entropy, information gain) in splits of each tree, subsampling rows and columns, ...
- On the other hand, in RandomForest, trees are independent, so multiple cores can be employed in the constructing processes.

## 3. Feature preprocessing and generation with respect to models

4 *questions*

1. Suppose we have a feature with all the values between 0 and 1 except few outliers larger than 1. What can help us to decrease outliers' influence on non-tree models?

*Answer:*

- Apply rank transform to the features
- Winsorization

2. Suppose we fit a tree-based model. In which cases label encoding can be better to use than one-hot encoding?

*Answer:*

- When the number of categorical features in the dataset is huge
- When categorical feature is ordinal

3. Suppose we fit a tree-based model on several categorical features. In which cases applying one-hot encoding can be better to use than label-encoding?

*Answer:*

- If target dependence on the label encoded feature is very non-linear, i.e. values that are close to each other in the label encode feature correspond to target values that aren't close.

4. Suppose we have a categorical feature and a linear model. We need to somehow encode this feature. Which of the following statements are true?

*Answer:*

- Depending on the dataset either of label encoder or one-hot encoder could be better

## 4. Feature extraction from text and images

4 *questions*

1. Select true statements about n-grams

*Answer:*

- N-grams can help utilize local context around each word.
- N-grams features are typically sparse.
- Levenshteining should always be applied before computing n-grams.

Explanation:

- First statement: because N-grams method split a sequence int sub-sequences containing a word and its neighbors.
- Second statement: because number of gram is typically large
- Last statement: I think this statement is true because I implicitly understand that *"Levenshteining"* means Levenshtein distance between 2 sequences, which should be calculated before splitting it into sub-sequences. If my understanding is incorrect, may neither this statement.
- *"N-grams always help increase significance of important words"* : this statement is false, because N-grams scores does not correlate with important words. On the other hand, this property is of Tf-Idf method, where important words would have high tf-idf scores.

2. Select true statements.

*Answer:*

- Bag of words usually produces longer vectors than Word2vec
- Meaning of each value in BOW matrix is unknown.
- You do not need bag of words features in a competition if you have word2vec features.

Explanation:

- It's very clear that word2vec features are always better than BOW.
- "Semantically similar words usually have similar word2vec embeddings" : this statement is a little bit confused, because actually semantically similar words only have **close** , not **similar**, word2vec embeddings.

3. Suppose in a new competition we are given a dataset of 2D medical images. We want to extract image descriptors from a hidden layer of a neural network pretrained on the ImageNet dataset. We will then use extracted descriptors to train a simple logistic regression model to classify images from our dataset.

We consider to use two networks: ResNet-50 with imagenet accuracy of X and VGG-16 with imageNet accuracy of Y (X < Y). Select true statements.

*Answer:*

- It is not clear what descriptors are better on our dataset. We should evaluate both.

*Explanation:*

- With one pretrained CNN model, for an image, we can get multiple vector of descriptors each from a layer.
- Descriptors from the above 2 models aren't always similar in cosine distance, it depends on which layer we extract from.
- Although ResNet-50 outperformed VGG-16 on Imagenet dataset in term of accuracy, we cannot conclude that it also better on our dataset, because the two datasets are from two different domains.

4. Data augmentation can be used at (1) train time (2) test time

Answer:

- True, True.

Explanation:

- Usually in test time, we do not augment data as in train time.
- But sometimes, we can augment input and received multiple corresponding outputs from model. Then, we can apply any ensemble method on the outputs, such as voting, averaging, ... to get a more robust prediction.
- For example, in image retrieval task, rather than embedding vector obtained from the original input image, we can extract another embedding vector from horizontal flip version of it, then average or concatenate the 2 vectors to form a more robust embedding. Ignore the drawback that this method would increase latency, it increase significantly accuracy reported in many papers.

---

---